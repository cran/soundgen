% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/analyze.R
\name{analyze}
\alias{analyze}
\title{Analyze sound}
\usage{
analyze(x, samplingRate = NULL, dynamicRange = 80, silence = 0.04,
  scale = NULL, SPL_measured = 70, Pref = 2e-05, windowLength = 50,
  step = NULL, overlap = 50, wn = "gaussian", zp = 0,
  cutFreq = min(samplingRate/2, max(7000, pitchCeiling * 2)),
  nFormants = 3, pitchMethods = c("autocor", "spec", "dom"),
  entropyThres = 0.6, pitchFloor = 75, pitchCeiling = 3500,
  priorMean = 300, priorSD = 6, priorPlot = "deprecated",
  nCands = 1, minVoicedCands = NULL, domThres = 0.1,
  domSmooth = 220, autocorThres = 0.7, autocorSmooth = NULL,
  cepThres = 0.3, cepSmooth = 400, cepZp = 0, specThres = 0.3,
  specPeak = 0.35, specSinglePeakCert = 0.4, specHNRslope = 0.8,
  specSmooth = 150, specMerge = 1, shortestSyl = 20,
  shortestPause = 60, interpolWin = 75, interpolTol = 0.3,
  interpolCert = 0.3, pathfinding = c("none", "fast", "slow")[2],
  annealPars = list(maxit = 5000, temp = 1000), certWeight = 0.5,
  snakeStep = 0.05, snakePlot = FALSE, smooth = 1,
  smoothVars = c("pitch", "dom"), summary = FALSE,
  summaryFun = c("mean", "median", "sd"), plot = TRUE,
  showLegend = TRUE, savePath = NA, plotSpec = "deprecated",
  osc = TRUE, osc_dB = FALSE, pitchPlot = list(col = rgb(0, 0, 1,
  0.75), lwd = 3), candPlot = list(), ylim = NULL, xlab = "Time, ms",
  ylab = "kHz", main = NULL, width = 900, height = 500,
  units = "px", res = NA, ...)
}
\arguments{
\item{x}{path to a .wav or .mp3 file or a vector of amplitudes with specified
samplingRate}

\item{samplingRate}{sampling rate of \code{x} (only needed if \code{x} is a
numeric vector, rather than an audio file)}

\item{dynamicRange}{dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero}

\item{silence}{(0 to 1) frames with RMS amplitude below silence threshold are
not analyzed at all. NB: this number is dynamically updated: the actual
silence threshold may be higher depending on the quietest frame, but it
will never be lower than this specified number.}

\item{scale}{maximum possible amplitude of input used for normalization of
input vector (not needed if input is an audio file)}

\item{SPL_measured}{sound pressure level at which the sound is presented, dB
(set to 0 to skip analyzing subjective loudness)}

\item{Pref}{reference pressure, Pa}

\item{windowLength}{length of FFT window, ms}

\item{step}{you can override \code{overlap} by specifying FFT step, ms}

\item{overlap}{overlap between successive FFT frames, \%}

\item{wn}{window type: gaussian, hanning, hamming, bartlett, rectangular,
blackman, flattop}

\item{zp}{window length after zero padding, points}

\item{cutFreq}{(2 * pitchCeiling to Nyquist, Hz) repeat the calculation of
spectral descriptives after discarding all info above \code{cutFreq}.
Recommended if the original sampling rate varies across different analyzed
audio files. Note that "entropyThres" applies only to this frequency range,
which also affects which frames will not be analyzed with pitchAutocor.}

\item{nFormants}{the number of formants to extract per STFT frame (0 = no
formant analysis). Calls \code{\link[phonTools]{findformants}} with default
settings}

\item{pitchMethods}{methods of pitch estimation to consider for determining
pitch contour: 'autocor' = autocorrelation (~PRAAT), 'cep' = cepstral,
'spec' = spectral (~BaNa), 'dom' = lowest dominant frequency band ('' or
NULL = no pitch analysis)}

\item{entropyThres}{pitch tracking is not performed for frames with Weiner
entropy above \code{entropyThres}, but other spectral descriptives are
still calculated}

\item{pitchFloor, pitchCeiling}{absolute bounds for pitch candidates (Hz)}

\item{priorMean, priorSD}{specifies the mean (Hz) and standard deviation
(semitones) of gamma distribution describing our prior knowledge about the
most likely pitch values for this file. For ex., \code{priorMean = 300,
priorSD = 6} gives a prior with mean = 300 Hz and SD = 6 semitones (half
an octave)}

\item{priorPlot}{deprecated; use \code{\link{getPrior}} to visualize the
prior}

\item{nCands}{maximum number of pitch candidates per method (except for
\code{dom}, which returns at most one candidate per frame), normally 1...4}

\item{minVoicedCands}{minimum number of pitch candidates that have to be
defined to consider a frame voiced (if NULL, defaults to 2 if \code{dom} is
among other candidates and 1 otherwise)}

\item{domThres}{(0 to 1) to find the lowest dominant frequency band, we
do short-term FFT and take the lowest frequency with amplitude at least
domThres}

\item{domSmooth}{the width of smoothing interval (Hz) for finding
\code{dom}}

\item{autocorThres, cepThres, specThres}{(0 to 1) separate
voicing thresholds for detecting pitch candidates with three different
methods: autocorrelation, cepstrum, and BaNa algorithm (see Details). Note
that HNR is calculated even for unvoiced frames.}

\item{autocorSmooth}{the width of smoothing interval (in bins) for
finding peaks in the autocorrelation function. Defaults to 7 for sampling
rate 44100 and smaller odd numbers for lower values of sampling rate}

\item{cepSmooth}{the width of smoothing interval (Hz) for finding peaks in
the cepstrum}

\item{cepZp}{zero-padding of the spectrum used for cepstral pitch detection
(final length of spectrum after zero-padding in points, e.g. 2 ^ 13)}

\item{specPeak, specHNRslope}{when looking for putative harmonics in
the spectrum, the threshold for peak detection is calculated as
\code{specPeak * (1 - HNR * specHNRslope)}}

\item{specSinglePeakCert}{(0 to 1) if F0 is calculated based on a single
harmonic ratio (as opposed to several ratios converging on the same
candidate), its certainty is taken to be \code{specSinglePeakCert}}

\item{specSmooth}{the width of window for detecting peaks in the spectrum, Hz}

\item{specMerge}{pitch candidates within \code{specMerge} semitones are
merged with boosted certainty}

\item{shortestSyl}{the smallest length of a voiced segment (ms) that
constitutes a voiced syllable (shorter segments will be replaced by NA, as
if unvoiced)}

\item{shortestPause}{the smallest gap between voiced syllables (ms) that
means they shouldn't be merged into one voiced syllable}

\item{interpolWin, interpolTol, interpolCert}{control the behavior of
interpolation algorithm when postprocessing pitch candidates. To turn off
interpolation, set \code{interpolWin = 0}. See \code{soundgen:::pathfinder}
for details.}

\item{pathfinding}{method of finding the optimal path through pitch
candidates: 'none' = best candidate per frame, 'fast' = simple heuristic,
'slow' = annealing. See \code{soundgen:::pathfinder}}

\item{annealPars}{a list of control parameters for postprocessing of
pitch contour with SANN algorithm of \code{\link[stats]{optim}}. This is
only relevant if \code{pathfinding = 'slow'}}

\item{certWeight}{(0 to 1) in pitch postprocessing, specifies how much we
prioritize the certainty of pitch candidates vs. pitch jumps / the internal
tension of the resulting pitch curve}

\item{snakeStep}{optimized path through pitch candidates is further
processed to minimize the elastic force acting on pitch contour. To
disable, set \code{snakeStep = 0}}

\item{snakePlot}{if TRUE, plots the snake}

\item{smooth, smoothVars}{if \code{smooth} is a positive number, outliers of
the variables in \code{smoothVars} are adjusted with median smoothing.
\code{smooth} of 1 corresponds to a window of ~100 ms and tolerated
deviation of ~4 semitones. To disable, set \code{smooth = 0}}

\item{summary}{if TRUE, returns only a summary of the measured acoustic
variables (mean, median and SD). If FALSE, returns a list containing
frame-by-frame values}

\item{summaryFun}{a vector of names of functions used to summarize each
acoustic characteristic}

\item{plot}{if TRUE, produces a spectrogram with pitch contour overlaid}

\item{showLegend}{if TRUE, adds a legend with pitch tracking methods}

\item{savePath}{if a valid path is specified, a plot is saved in this folder
(defaults to NA)}

\item{plotSpec}{deprecated}

\item{osc}{should an oscillogram be shown under the spectrogram? TRUE/
FALSE. If `osc_dB`, the oscillogram is displayed on a dB scale. See
\code{\link{osc_dB}} for details}

\item{osc_dB}{should an oscillogram be shown under the spectrogram? TRUE/
FALSE. If `osc_dB`, the oscillogram is displayed on a dB scale. See
\code{\link{osc_dB}} for details}

\item{pitchPlot}{a list of graphical parameters for displaying the final
pitch contour. Set to \code{NULL} or \code{NA} to suppress}

\item{candPlot}{a list of graphical parameters for displaying
individual pitch candidates. Set to \code{NULL} or \code{NA} to suppress}

\item{ylim}{frequency range to plot, kHz (defaults to 0 to Nyquist frequency)}

\item{xlab, ylab, main}{plotting parameters}

\item{width, height, units, res}{parameters passed to
\code{\link[grDevices]{png}} if the plot is saved}

\item{...}{other graphical parameters passed to \code{\link{spectrogram}}}
}
\value{
If \code{summary = TRUE}, returns a dataframe with one row and three
  columns per acoustic variable (mean / median / SD). If \code{summary =
  FALSE}, returns a dataframe with one row per STFT frame and one column per
  acoustic variable. The best guess at the pitch contour considering all
  available information is stored in the variable called "pitch". In
  addition, the output contains pitch estimates by separate algorithms
  included in \code{pitchMethods} and a number of other acoustic descriptors:
  \describe{
  \item{duration}{total duration, s}
  \item{duration_noSilence}{duration from the beginning of the first
  non-silent STFT frame to the end of the last non-silent STFT frame, s (NB:
  depends strongly on \code{windowLength} and \code{silence} settings)}
  \item{time}{time of the middle of each frame (ms)} \item{ampl}{root mean
  square of amplitude per frame, calculated as sqrt(mean(frame ^ 2))}
  \item{amplVoiced}{the same as ampl for voiced frames and NA for unvoiced
  frames} \item{dom}{lowest dominant frequency band (Hz) (see "Pitch tracking
  methods / Dominant frequency" in the vignette)} \item{entropy}{Weiner
  entropy of the spectrum of the current frame. Close to 0: pure tone or
  tonal sound with nearly all energy in harmonics; close to 1: white noise}
  \item{f1_freq, f1_width, ...}{the frequency and bandwidth of the first
  nFormants formants per STFT frame, as calculated by phonTools::findformants
  with default settings} \item{harmonics}{the amount of energy in upper
  harmonics, namely the ratio of total spectral mass above 1.25 x F0 to the
  total spectral mass below 1.25 x F0 (dB)} \item{HNR}{harmonics-to-noise
  ratio (dB), a measure of harmonicity returned by soundgen:::getPitchAutocor
  (see "Pitch tracking methods / Autocorrelation"). If HNR = 0 dB, there is
  as much energy in harmonics as in noise} \item{loudness}{subjective
  loudness, in sone, corresponding to the chosen SPL_measured - see
  \code{\link{getLoudness}}} \item{medianFreq}{50th quantile of the frame's
  spectrum} \item{peakFreq}{the frequency with maximum spectral power (Hz)}
  \item{peakFreqCut}{the frequency with maximum spectral power below cutFreq
  (Hz)} \item{pitch}{post-processed pitch contour based on all F0 estimates}
  \item{pitchAutocor}{autocorrelation estimate of F0}
  \item{pitchCep}{cepstral estimate of F0} \item{pitchSpec}{BaNa estimate of
  F0} \item{quartile25, quartile50, quartile75}{the 25th, 50th, and 75th
  quantiles of the spectrum below cutFreq (Hz)} \item{specCentroid}{the
  center of gravity of the frame’s spectrum, first spectral moment (Hz)}
  \item{specCentroidCut}{the center of gravity of the frame’s spectrum below
  cutFreq} \item{specSlope}{the slope of linear regression fit to the
  spectrum below cutFreq} \item{voiced}{is the current STFT frame voiced? TRUE
  / FALSE}
}
}
\description{
Acoustic analysis of a single sound file: pitch tracking, basic spectral
characteristics, and estimated loudness (see \code{\link{getLoudness}}). The
default values of arguments are optimized for human non-linguistic
vocalizations. See vignette('acoustic_analysis', package = 'soundgen') for
details.
}
\examples{
sound = soundgen(sylLen = 300, pitch = c(900, 400, 2300),
  noise = list(time = c(0, 300), value = c(-40, 0)),
  temperature = 0.001,
  addSilence = 50)  # NB: always have some silence before and after!!!
# playme(sound, 16000)
a = analyze(sound, samplingRate = 16000, plot = TRUE)

\dontrun{
# For maximum processing speed (just basic spectral descriptives):
a = analyze(sound, samplingRate = 16000,
  plot = FALSE,         # no plotting
  pitchMethods = NULL,  # no pitch tracking
  SPL_measured = 0,     # no loudness analysis
  nFormants = 0         # no formant analysis
)

sound1 = soundgen(sylLen = 900, pitch = list(
  time = c(0, .3, .9, 1), value = c(300, 900, 400, 2300)),
  noise = list(time = c(0, 300), value = c(-40, 0)),
  temperature = 0.001)
# improve the quality of postprocessing:
a1 = analyze(sound1, samplingRate = 16000, priorSD = 24,
             plot = TRUE, pathfinding = 'slow')
median(a1$pitch, na.rm = TRUE)
# (can vary, since postprocessing is stochastic)
# compare to the true value:
median(getSmoothContour(anchors = list(time = c(0, .3, .8, 1),
  value = c(300, 900, 400, 2300)), len = 1000))

# the same pitch contour, but harder to analyze b/c of
subharmonics and jitter
sound2 = soundgen(sylLen = 900, pitch = list(
  time = c(0, .3, .8, 1), value = c(300, 900, 400, 2300)),
  noise = list(time = c(0, 900), value = c(-40, 0)),
  subDep = 100, jitterDep = 0.5, nonlinBalance = 100, temperature = 0.001)
# playme(sound2, 16000)
a2 = analyze(sound2, samplingRate = 16000, priorSD = 24,
             plot = TRUE, pathfinding = 'slow')
# many candidates are off, but the overall contour should be mostly accurate

# Fancy plotting options:
a = analyze(sound2, samplingRate = 16000, plot = TRUE,
  xlab = 'Time, ms', colorTheme = 'seewave',
  contrast = .5, ylim = c(0, 4),
  pitchMethods = c('dom', 'autocor', 'spec'),
  candPlot = list(
    col = c('gray70', 'yellow', 'purple'),  # same order as pitchMethods
    pch = c(1, 3, 5),
    cex = 3),
  pitchPlot = list(col = 'black', lty = 3, lwd = 3),
  osc_dB = TRUE, heights = c(2, 1))

# Different formatting options for output
a = analyze(sound2, samplingRate = 16000, summary = FALSE)  # frame-by-frame
a = analyze(sound2, samplingRate = 16000, summary = TRUE,
            summaryFun = c('mean', 'range'))  # one row per sound
# ...with custom summaryFun
difRan = function(x) diff(range(x))
a = analyze(sound2, samplingRate = 16000, summary = TRUE,
            summaryFun = c('mean', 'difRan'))

# Save the plot
a = analyze(sound, samplingRate = 16000,
            savePath = '~/Downloads/',
            width = 20, height = 15, units = 'cm', res = 300)

## Amplitude and loudness: analyze() should give the same results as
dedicated functions getRMS() / getLoudness()
# Create 1 kHz tone
samplingRate = 16000; dur_ms = 50
sound1 = sin(2*pi*1000/samplingRate*(1:(dur_ms/1000*samplingRate)))
a1 = analyze(sound1, samplingRate = samplingRate, windowLength = 25,
        overlap = 50, SPL_measured = 40, scale = 1,
        pitchMethods = NULL, plot = FALSE)
a1$loudness  # loudness per STFT frame (1 sone by definition)
getLoudness(sound1, samplingRate = samplingRate, windowLength = 25,
            overlap = 50, SPL_measured = 40, scale = 1)$loudness
a1$ampl  # RMS amplitude per STFT frame
getRMS(sound1, samplingRate = samplingRate, windowLength = 25,
       overlap = 50, scale = 1)
# or even simply: sqrt(mean(sound1 ^ 2))

# The same sound as above, but with half the amplitude
a_half = analyze(sound1/2, samplingRate = samplingRate, windowLength = 25,
        overlap = 50, SPL_measured = 40, scale = 1,
        pitchMethods = NULL, plot = FALSE)
a1$ampl / a_half$ampl  # rms amplitude halved
a1$loudness/ a_half$loudness  # loudness is not a linear function of amplitude

# Amplitude & loudness of an existing audio file
sound2 = '~/Downloads/temp/032_ut_anger_30-m-roar-curse.wav'
a2 = analyze(sound2, windowLength = 25, overlap = 50, SPL_measured = 40,
        pitchMethods = NULL, plot = FALSE)
apply(a2[, c('loudness', 'ampl')], 2, median, na.rm = TRUE)
median(getLoudness(sound2, windowLength = 25, overlap = 50,
                   SPL_measured = 40)$loudness)
median(getRMS(sound2, windowLength = 25, overlap = 50, scale = 1))
}
}
\seealso{
\code{\link{analyzeFolder}} \code{\link{pitch_app}}
  \code{\link{getLoudness}} \code{\link{segment}} \code{\link{getRMS}}
  \code{\link{modulationSpectrum}} \code{\link{ssm}}
}
